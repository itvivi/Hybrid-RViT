{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "install libraries"
      ],
      "metadata": {
        "id": "iL4HCj8KkNB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "!pip install tensorflow_addons\n",
        "!pip install np_utils"
      ],
      "metadata": {
        "id": "lEK0ZfSHkGDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libraries"
      ],
      "metadata": {
        "id": "cThLP-W2kIOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJu4UCXWfgtQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import copy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import cv2\n",
        "import shap\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from tensorflow.keras.layers import Conv2D, Reshape, Embedding, Concatenate, Dense, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import np_utils\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import tensorflow_addons as tfa\n",
        "from keras.src.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "vfWhkr2wkpTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = mpimg.imread('/content/Alzheimer_s Dataset/ADimage.jpg')# Read an image from your filesystem\n",
        "plt.imshow(image)  # Display the image\n",
        "plt.title('true class:AD,predicted class:AD')# Add a title (optional)\n",
        "plt.show()  # Show the image\n"
      ],
      "metadata": {
        "id": "2A0asgg1hLBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=128\n",
        "h=128\n",
        "label_to_class = {\n",
        "    'MildDemented': 0,\n",
        "    'ModerateDemented': 1,\n",
        "    'NonDemented': 2,\n",
        "    'VeryMildDemented':3\n",
        "\n",
        "\n",
        "}\n",
        "class_to_label = {v: k for k, v in label_to_class.items()}\n",
        "n_classes = len(label_to_class)\n",
        "\n",
        "def get_images(dir_name='/content/Alzheimer_s Dataset', label_to_class=label_to_class):\n",
        "#read images / labels from directory\n",
        "\n",
        "    Images = []\n",
        "    Classes = []\n",
        "\n",
        "    for j in ['/train','/test']:\n",
        "        for label_name in os.listdir(dir_name+str(j)):\n",
        "            cls1 = label_to_class[label_name]\n",
        "\n",
        "            for img_name in os.listdir('/'.join([dir_name+str(j), label_name])):\n",
        "                # Load the image\n",
        "                img = load_img('/'.join([dir_name+str(j), label_name, img_name]), target_size=(w, h))\n",
        "\n",
        "                # Convert the image to a NumPy array\n",
        "                img = img_to_array(img)\n",
        "\n",
        "                Images.append(img)\n",
        "                Classes.append(cls1)\n",
        "\n",
        "    Images = np.array(Images, dtype=np.float16)\n",
        "    Classes = np.array(Classes, dtype=np.float16)\n",
        "    Images, Classes = shuffle(Images, Classes, random_state=0)\n",
        "\n",
        "    return Images, Classes"
      ],
      "metadata": {
        "id": "LwlOVe5yjMts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Images, Classes = get_images()"
      ],
      "metadata": {
        "id": "jfUX7z4Ak8hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_train, indices_test = train_test_split(list(range(Images.shape[0])),train_size=0.8, test_size=0.2, shuffle=True)\n",
        "x_train = Images[indices_train]\n",
        "y_train = Classes[indices_train]\n",
        "x_test = Images[indices_test]\n",
        "y_test = Classes[indices_test]"
      ],
      "metadata": {
        "id": "OAav3rjBmI6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train, num_classes=n_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=n_classes)"
      ],
      "metadata": {
        "id": "qr5blweXmSgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassToken(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(ClassToken, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = self.add_weight(shape=(1, 1, input_shape[-1]), initializer=w_init, trainable=True )\n",
        "       #self.w = tf.Variable(initial_value=w_init(shape=(1, 1, input_shape[-1]),dtype=np.float32), trainable=True )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        hidden_dim = self.w.shape[-1]\n",
        "\n",
        "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
        "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
        "\n",
        "        return cls"
      ],
      "metadata": {
        "id": "Qa-jbP5ymW-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, cf):\n",
        "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    x = Dense(cf[\"hidden_dim\"])(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "FfG0QSBAmZXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(x, cf):\n",
        "    skip_1 = x\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "    x = tf.keras.layers.MultiHeadAttention(num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"])(x, x)\n",
        "    x = tf.keras.layers.Add()([x, skip_1])\n",
        "    x = tf.keras.layers.Dropout(cf[\"dropout_rate\"])(x)\n",
        "\n",
        "    skip_2 = x\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "    x = mlp(x, cf)\n",
        "    x = tf.keras.layers.Add()([x, skip_2])\n",
        "    x = tf.keras.layers.Dropout(cf[\"dropout_rate\"])(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "a15uN2fkmdV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50ViT(cf):\n",
        "    input_shape = (cf[\"image_size\"], cf[\"image_size\"], cf[\"num_channels\"])\n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape) ## (None, 128, 128, 3)\n",
        "\n",
        "    \"\"\" Pre-trained Resnet50 \"\"\"\n",
        "    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "    output = resnet50.output ## (None, 4, 4, 2048)\n",
        "\n",
        "    \"\"\" Patch Embeddings \"\"\"\n",
        "    patch_embed = Conv2D(cf[\"hidden_dim\"], kernel_size=cf[\"patch_size\"], padding=\"same\")(output) ##(None, 1, 1, 64)\n",
        "\n",
        "    patch_embed = BatchNormalization()(patch_embed)\n",
        "    _, h, w, f = patch_embed.shape\n",
        "    patch_embed = Reshape((h*w, f))(patch_embed) ## (None, 1, 64)\n",
        "\n",
        "    \"\"\" Position Embeddings \"\"\"\n",
        "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1) ## (16,)\n",
        "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (16, 64)\n",
        "\n",
        "    \"\"\" Patch + Position Embeddings \"\"\"\n",
        "    embed = patch_embed + pos_embed ## (None, 16, 64)\n",
        "\n",
        "    \"\"\" Adding Class Token \"\"\"\n",
        "    token = ClassToken()(embed)\n",
        "    x = Concatenate(axis=1)([token, embed]) ## (None, 17, 64)\n",
        "\n",
        "    \"\"\" Transformer Encoder \"\"\"\n",
        "    for _ in range(cf[\"num_layers\"]):\n",
        "        x = transformer_encoder(x, cf)\n",
        "\n",
        "    x = LayerNormalization()(x)\n",
        "    x = x[:, 0, :]\n",
        "    logits = Dense(cf[\"num_classes\"])(x)\n",
        "\n",
        "    model = Model(inputs, logits)\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "z6QoVc8HmfsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameter settings\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config = {}\n",
        "    config[\"num_layers\"] = 6\n",
        "    config[\"hidden_dim\"] = 64\n",
        "    config[\"mlp_dim\"] = 2048\n",
        "    config[\"num_heads\"] = 8\n",
        "    config[\"dropout_rate\"] = 0.2#0.1\n",
        "\n",
        "    config[\"image_size\"] = 128\n",
        "    config[\"patch_size\"] = 32\n",
        "    config[\"num_patches\"] = int(config[\"image_size\"]**2 / config[\"patch_size\"]**2)\n",
        "    config[\"num_channels\"] = 3\n",
        "    config[\"num_classes\"] = 4"
      ],
      "metadata": {
        "id": "C_7rF3lmmpk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=0.00005 , weight_decay=0.0001\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
        "            #keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/ontent/workingmodel/weights1.h5\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=16,\n",
        "        epochs=10,\n",
        "        validation_data=(x_test, y_test),\n",
        "        validation_split=0.2,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "    model.save_weights(\n",
        "    checkpoint_filepath,\n",
        "    overwrite=True,\n",
        "    )\n",
        "    y_pred=model.predict(x_test)\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy = model.evaluate(x_test, y_test)  #, top_5_accuracy\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    #print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "nA3a6FEPm5US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    vit_classifier = ResNet50ViT(config)\n",
        "    history = run_experiment(vit_classifier)"
      ],
      "metadata": {
        "id": "0d-bOWFFnJ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],label='Training_accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label='Validation_accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training Accuracy vs Validation Accuracy')\n",
        "plt.xlabel('No.of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "plt.savefig('Accuracy_Graph')"
      ],
      "metadata": {
        "id": "P6xQyz9bnMsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],label='Training_loss')\n",
        "plt.plot(history.history['val_loss'],label='Validation_loss')\n",
        "plt.legend()\n",
        "plt.title('Training loss vs Validation loss')\n",
        "plt.xlabel('No.of epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "plt.savefig('Loss_Graph')"
      ],
      "metadata": {
        "id": "B5rkjlEWnRMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "target_names=['NC:0','EMCI:1','MCI:2','AD:3']\n",
        "print(classification_report(y_test,y_pred,target_names=target_names,digits=2))\n",
        "import seaborn as sns\n",
        "f = sns.heatmap(cm, annot=True, fmt='d')  #confusion matrix plot"
      ],
      "metadata": {
        "id": "PTJebaJlnWk0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}